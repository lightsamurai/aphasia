{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing (ball, flower)\n",
      "Final score: 0.15740902721881866\n",
      "Target word (ball) has a difficulty rating!\n",
      "\n",
      "Now processing (bridge, table)\n",
      "Final score: 0.09458004683256149\n",
      "Target word (bridge) has a difficulty rating!\n",
      "\n",
      "Now processing (kittens, cat)\n",
      "Found a match in MEN database for (kittens, cat)!\n",
      "Distance from word2vec and MEN: 0.3412886667251587\n",
      "Final score: 0.8093556666374206\n",
      "Target word (kittens) has a difficulty rating!\n",
      "\n",
      "Now processing (kittens, glass)\n",
      "Final score: 0.11298742145299911\n",
      "Target word (kittens) has a difficulty rating!\n",
      "\n",
      "Now processing (banana, apple)\n",
      "Final score: 0.5318406224250793\n",
      "Target word (banana) has a difficulty rating!\n",
      "\n",
      "Now processing (ball, apple)\n",
      "Final score: 0.1296665519475937\n",
      "Target word (ball) has a difficulty rating!\n",
      "\n",
      "Now processing (cat, glass)\n",
      "Final score: 0.12175223231315613\n",
      "Target word (cat) has a difficulty rating!\n",
      "\n",
      "The Spearman correlation for this dataset is: -0.12848904218751164\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOW_PROCESSING = \"Now processing ({0}, {1})\"\n",
    "FOUND_MATCH = \"Found a match in MEN database for ({0}, {1})!\"\n",
    "MEN_DISTANCE = \"Distance from word2vec and MEN: {0}\"\n",
    "DONE = \"Final score: {0}\"\n",
    "\n",
    "FOUND_CORRELATION = \"Target word ({0}) has a difficulty rating!\"\n",
    "CORRELATION = \"The Spearman correlation for this dataset is: {0}\"\n",
    "\n",
    "def main():\n",
    "    # Load our models\n",
    "    wv = api.load(\"word2vec-google-news-300\")\n",
    "    men = tupleize(\"data/men.csv\")\n",
    "\n",
    "    # First, extract our target - response pairs\n",
    "    input = tupleize(\"input.csv\")\n",
    "\n",
    "    # Of course we are also going to need some \"difficulty\" metric\n",
    "    difficulty = dict(tupleize(\"data/difficulty.csv\"))\n",
    "    # This will contain tuples with the target word, its difficulty\n",
    "    # and the final score (relative to the response word)\n",
    "    correlation = []\n",
    "\n",
    "    # Then, get similarity estimates from our models\n",
    "    with open(\"output.csv\", \"w\") as output:\n",
    "        for target, response in input:\n",
    "            print(NOW_PROCESSING.format(target, response));\n",
    "            wvScore = wv.similarity(target, response)\n",
    "\n",
    "            # If available, extract similarity estimate\n",
    "            # from MAN as well...\n",
    "            match = [score for score in men if (target in score\n",
    "                                            and response in score)]\n",
    "\n",
    "            if len(match) > 0:\n",
    "                # If found normalize it...\n",
    "                print(FOUND_MATCH.format(target, response))\n",
    "                menScore = float(match[0][2]) / 50.0\n",
    "                # ...find the vector distance from the two models...\n",
    "                distance = abs(menScore - wvScore)\n",
    "                print(MEN_DISTANCE.format(distance))\n",
    "                # ...and get a final value as the mean of the two scores\n",
    "                meanScore = mean([wvScore, menScore])\n",
    "            else:\n",
    "                # Too bad, can't do anything about it...\n",
    "                meanScore = wvScore\n",
    "\n",
    "            print(DONE.format(meanScore));\n",
    "            # Write our results in output.csv\n",
    "            output.write(\", \".join([target, response, str(meanScore)]))\n",
    "            output.write(\"\\n\")\n",
    "\n",
    "            # Now working on our correlation coefficient\n",
    "            #\n",
    "            # First, we need to keep track of which target words\n",
    "            # have a difficulty score associated to them. We'll only\n",
    "            # be able to use those to calculate our correlation coefficient.\n",
    "\n",
    "            if target in difficulty:\n",
    "                print(FOUND_CORRELATION.format(target), end=\"\\n\\n\")\n",
    "                # Keep track of the word, its difficulty score and the mean\n",
    "                # similarity with the response word.\n",
    "                # Of course there can be more than one entry for a\n",
    "                # given target word.\n",
    "                tuple = (target, float(difficulty[target]), meanScore)\n",
    "                correlation.append(tuple)\n",
    "\n",
    "    # Now that we know which target words can be used\n",
    "    # for the evaluation of our correlation coefficient\n",
    "    # we need to construct the variables' rankings.\n",
    "    xrank = rank([i[1] for i in correlation], False)\n",
    "    yrank = rank([i[2] for i in correlation], True)\n",
    "\n",
    "    covariance = cov(list(zip(xrank, yrank)))\n",
    "\n",
    "    spearman = covariance / math.sqrt(var(xrank) * var(yrank))\n",
    "    print(CORRELATION.format(spearman))\n",
    "\n",
    "    # Might be interesting...\n",
    "    plt.scatter(xrank, yrank)\n",
    "    plt.show()\n",
    "\n",
    "# Quick&dirty implementation of the fractional sorting\n",
    "# algo, Spearman works best with this...\n",
    "def rank(data, sorting = False):\n",
    "    ranking = []\n",
    "    occurrences = {}\n",
    "\n",
    "    for value in data:\n",
    "        if value in occurrences:\n",
    "            occurrences[value] += 1\n",
    "        else:\n",
    "            occurrences[value] = 1\n",
    "\n",
    "    unique = list(occurrences.keys())\n",
    "    unique.sort(reverse = sorting)\n",
    "\n",
    "    for value in data:\n",
    "        position = 1\n",
    "        for rank in unique:\n",
    "            if rank != value:\n",
    "                position += occurrences[rank]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        position += (occurrences[value] - 1) / 2\n",
    "        ranking.append(position)\n",
    "\n",
    "    return ranking\n",
    "\n",
    "def cov(data):\n",
    "    mux = mean([i[0] for i in data])\n",
    "    muy = mean([i[1] for i in data])\n",
    "\n",
    "    ret = sum([(i[0] - mux) * (i[1] - muy) for i in data]) / (len(data) - 1)\n",
    "    return ret\n",
    "\n",
    "def var(data):\n",
    "    return cov([(i, i) for i in data])\n",
    "\n",
    "def mean(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def tupleize(file):\n",
    "    output = []\n",
    "    with open(file, \"r\") as input:\n",
    "        line = input.readline()\n",
    "        while line:\n",
    "            nuple = tuple(line.rstrip().split(\", \"))\n",
    "            output.append(nuple)\n",
    "            line = input.readline();\n",
    "\n",
    "    return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "else:\n",
    "    print(\"Please run as main.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN QUA FUNZIONA, non toccare sopra!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2cdec1b5a03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please run as main.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2cdec1b5a03c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Then, get similarity estimates from our models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOW_PROCESSING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mwvScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOW_PROCESSING = \"Now processing ({0}, {1})\"\n",
    "FOUND_MATCH = \"Found a match in MEN database for ({0}, {1})!\"\n",
    "MEN_DISTANCE = \"Distance from word2vec and MEN: {0}\"\n",
    "DONE = \"Final score: {0}\"\n",
    "\n",
    "FOUND_CORRELATION = \"Target word ({0}) has a difficulty rating!\"\n",
    "CORRELATION = \"The Spearman correlation for this dataset is: {0}\"\n",
    "\n",
    "def main():\n",
    "    # Load our models\n",
    "    wv = api.load(\"word2vec-google-news-300\")\n",
    "    men = tupleize(\"data/men.csv\")\n",
    "    \n",
    "# tupleize = funzione definita sotto per trasformare in tuple i miei dati\n",
    "\n",
    "    # First, extract our target - response pairs\n",
    "    input = tupleize(\"input_pairs_EN.csv\")\n",
    "\n",
    "    # Of course we are also going to need some \"difficulty\" metric\n",
    "    difficulty = dict(tupleize(\"data/difficulty.csv\"))\n",
    "    \n",
    "    \n",
    "    # This will contain tuples with the target word, its difficulty\n",
    "    # and the final score (relative to the response word)\n",
    "    correlation = []\n",
    "\n",
    "    # Then, get similarity estimates from our models\n",
    "    with open(\"output.csv\", \"w\") as output:\n",
    "        for target, response in input:\n",
    "            print(NOW_PROCESSING.format(target, response));\n",
    "            wvScore = wv.similarity(target, response)\n",
    "\n",
    "            # If available, extract similarity estimate\n",
    "            # from MAN as well...\n",
    "            match = [score for score in men if (target in score\n",
    "                                            and response in score)]\n",
    "\n",
    "            if len(match) > 0:\n",
    "                # If found normalize it...\n",
    "                print(FOUND_MATCH.format(target, response))\n",
    "                menScore = float(match[0][2]) / 50.0\n",
    "                # ...find the vector distance from the two models...\n",
    "                distance = abs(menScore - wvScore)\n",
    "                print(MEN_DISTANCE.format(distance))\n",
    "                # ...and get a final value as the mean of the two scores\n",
    "                meanScore = mean([wvScore, menScore])\n",
    "            else:\n",
    "                # Too bad, can't do anything about it...\n",
    "                meanScore = wvScore\n",
    "\n",
    "            print(DONE.format(meanScore));\n",
    "            # Write our results in output.csv\n",
    "            output.write(\", \".join([target, response, str(meanScore)]))\n",
    "            output.write(\"\\n\")\n",
    "\n",
    "            # Now working on our correlation coefficient\n",
    "            #\n",
    "            # First, we need to keep track of which target words\n",
    "            # have a difficulty score associated to them. We'll only\n",
    "            # be able to use those to calculate our correlation coefficient.\n",
    "\n",
    "            if target in difficulty:\n",
    "                print(FOUND_CORRELATION.format(target), end=\"\\n\\n\")\n",
    "                # Keep track of the word, its difficulty score and the mean\n",
    "                # similarity with the response word.\n",
    "                # Of course there can be more than one entry for a\n",
    "                # given target word.\n",
    "                tuple = (target, float(difficulty[target]), meanScore)\n",
    "                correlation.append(tuple)\n",
    "\n",
    "    # Now that we know which target words can be used\n",
    "    # for the evaluation of our correlation coefficient\n",
    "    # we need to construct the variables' rankings.\n",
    "    xrank = rank([i[1] for i in correlation], False)\n",
    "    yrank = rank([i[2] for i in correlation], True)\n",
    "\n",
    "    covariance = cov(list(zip(xrank, yrank)))\n",
    "\n",
    "    spearman = covariance / math.sqrt(var(xrank) * var(yrank))\n",
    "    print(CORRELATION.format(spearman))\n",
    "\n",
    "    # Might be interesting...\n",
    "    plt.scatter(xrank, yrank)\n",
    "    plt.show()\n",
    "\n",
    "# Quick&dirty implementation of the fractional sorting\n",
    "# algo, Spearman works best with this...\n",
    "def rank(data, sorting = False):\n",
    "    ranking = []\n",
    "    occurrences = {}\n",
    "\n",
    "    for value in data:\n",
    "        if value in occurrences:\n",
    "            occurrences[value] += 1\n",
    "        else:\n",
    "            occurrences[value] = 1\n",
    "\n",
    "    unique = list(occurrences.keys())\n",
    "    unique.sort(reverse = sorting)\n",
    "\n",
    "    for value in data:\n",
    "        position = 1\n",
    "        for rank in unique:\n",
    "            if rank != value:\n",
    "                position += occurrences[rank]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        position += (occurrences[value] - 1) / 2\n",
    "        ranking.append(position)\n",
    "\n",
    "    return ranking\n",
    "\n",
    "def cov(data):\n",
    "    mux = mean([i[0] for i in data])\n",
    "    muy = mean([i[1] for i in data])\n",
    "\n",
    "    ret = sum([(i[0] - mux) * (i[1] - muy) for i in data]) / (len(data) - 1)\n",
    "    return ret\n",
    "\n",
    "def var(data):\n",
    "    return cov([(i, i) for i in data])\n",
    "\n",
    "def mean(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def tupleize(file):\n",
    "    output = []\n",
    "    with open(file, \"r\") as input:\n",
    "        line = input.readline()\n",
    "        while line:\n",
    "            nuple = tuple(line.rstrip().split(\", \"))\n",
    "            output.append(nuple)\n",
    "            line = input.readline();\n",
    "\n",
    "    return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "else:\n",
    "    print(\"Please run as main.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
