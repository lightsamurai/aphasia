{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aphasia patients' automatic diagnosing with WORD2VEC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this work is to automatically rank the severeness of anomic aphasia by applying Word2Vec tasks to our corpus, manually collected from the Aphasia Bank online database (https://aphasia.talkbank.org/) from diagnostic protocols. We analyze the transcriptions of aphasic patients' productions collected in Aphasia Talkbank, which were produced by the patients by accomplishing specific and standardized tasks of the Aphasia Bank Protocol (i.e. to describe the scene portraited in a picture the interviewer shows the patient). Word2vec uses a neural network model to learn word associations from a large corpus of text.\n",
    "\n",
    "We collect our input data from the Aphasia Bank online database. We organise our input data in a .csv file where the first column is the patient-ID, whereas the second and third column are target/response word pairs. The target is the word which exactly describes the scene (e.g. \"ball\") and the response is the word the patient produces (e.g. \"sphere\").\n",
    "\n",
    "Since the automatic diagnosing algorithm works for each language, a suited language model has to be uploaded (e.g. for the English language we use the pre-trained 'word2vec-google-news-300' vectors). The cosine similarity task is ran by the built-in wv.similarity function of Word2Vec, which takes as input our word pairs and gives as output their cosine similarity.\n",
    "\n",
    "More details on the project: https://drive.google.com/file/d/1IQ8PDOVlTTNE6CscvI70yfJL8G-CYuM5/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD the LANGUAGE MODEL for ENGLISH from Gensim - Google News 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the vectors we need for the comparison\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE MODEL FOR ITALIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ita = KeyedVectors.load(\"/_trained_models/MODEL_WIKI_plainstream/ord2vec_10mil_wiki.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the list of word pairs and put it in a list of lists\n",
    "\n",
    "def aphasia_diagnosing(pairs, model):\n",
    "    lista = []\n",
    "    for line in open(pairs).readlines():\n",
    "        lista.append(line.strip().split(\",\"))\n",
    "    lista_soggetti = []\n",
    "    for i in lista:\n",
    "        lista_soggetti.append(i[0])\n",
    "    \n",
    "# put all word pairs in a dictionary containing a list of lists associated to each key=patient\n",
    "    d = {} # build a catalog for all patients\n",
    "    for i in set(lista_soggetti):\n",
    "# for each unique value corresponding to each patient \n",
    "# create a list containing his/her [w1,w2, score]\n",
    "    \n",
    "        d[i] = []\n",
    "    for line in lista:\n",
    "        d[line[0]].append([(line[1].strip()), (line[2].strip())])\n",
    "\n",
    "# access each patient's data with d[\"n\"]\n",
    "\n",
    "    for i in d: # cycle the keys\n",
    "        for w_pair in d[i]: # cycle the elements in the list corresponding to the key\n",
    "            w1, w2 = w_pair\n",
    "            dist = model.similarity(w1, w2)\n",
    "            w_pair.append(dist)\n",
    "\n",
    "# one can access each patient's list of lists by calling the key = d[“n“]\n",
    "\n",
    "    lista_similarities = {}\n",
    "    for l in d.items():\n",
    "        somma = 0\n",
    "        for it in l[1]:\n",
    "            somma=somma+it[2]\n",
    "        media=somma/len(l[1])\n",
    "        lista_similarities[int(l[0])]=media\n",
    "    return lista_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.18128868884273938,\n",
       " 10: 0.24347134147371566,\n",
       " 11: 0.24217813448221595,\n",
       " 2: 0.38771220445632937,\n",
       " 9: 0.20249340832233428,\n",
       " 12: 0.33968087037404376,\n",
       " 8: 0.37051263451576233,\n",
       " 4: 0.440139077603817,\n",
       " 3: 0.12276173879702885,\n",
       " 7: 0.18245189115405083,\n",
       " 5: 0.36799256503582,\n",
       " 6: 0.19535352538029352}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of usage\n",
    "\n",
    "aphasia_diagnosing(\"/Users/silviafabbi/Desktop/aphasia/materials/input_EN.csv\", wv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
